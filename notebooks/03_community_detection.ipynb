{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Community Detection: Amazon Product Co-Purchasing Network\n",
        "\n",
        "This notebook performs community detection on the Amazon co-purchasing network using multiple algorithms and evaluates them against ground-truth communities.\n",
        "\n",
        "## Objectives:\n",
        "1. Load preprocessed graph and ground-truth communities\n",
        "2. Run all 3 community detection algorithms (Louvain, Label Propagation, Greedy Modularity)\n",
        "3. Compare execution times and performance\n",
        "4. Evaluate against ground truth using NMI and ARI\n",
        "5. Visualize results and analyze which algorithm performs best\n",
        "6. Generate insights and interpretations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n",
        "\n",
        "Import all necessary libraries for community detection, evaluation, and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path for imports\n",
        "if Path.cwd().name == 'notebooks':\n",
        "    project_root = Path.cwd().parent\n",
        "else:\n",
        "    project_root = Path.cwd()\n",
        "\n",
        "sys.path.insert(0, str(project_root / 'src'))\n",
        "os.chdir(project_root)\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Network analysis\n",
        "import networkx as nx\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Project modules\n",
        "from data_loader import load_saved_graph, load_communities\n",
        "from community_detection import (\n",
        "    run_all_community_detection,\n",
        "    get_community_sizes,\n",
        "    communities_to_dict\n",
        ")\n",
        "from community_evaluation import (\n",
        "    load_ground_truth_communities,\n",
        "    evaluate_communities,\n",
        "    compare_all_methods,\n",
        "    analyze_community_overlap\n",
        ")\n",
        "from community_visualization import (\n",
        "    plot_community_size_distribution,\n",
        "    plot_modularity_comparison,\n",
        "    plot_evaluation_metrics,\n",
        "    plot_largest_communities,\n",
        "    create_community_report\n",
        ")\n",
        "\n",
        "# Configure display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 50)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid' if 'seaborn-v0_8-darkgrid' in plt.style.available \n",
        "              else 'seaborn-darkgrid' if 'seaborn-darkgrid' in plt.style.available \n",
        "              else 'ggplot')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Preprocessed Graph and Ground-Truth Communities\n",
        "\n",
        "Load the cleaned graph and ground-truth communities for evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the preprocessed graph\n",
        "graph_path = \"data/processed/amazon_graph_cleaned.pkl\"\n",
        "print(f\"Loading graph from: {graph_path}\")\n",
        "G = load_saved_graph(graph_path)\n",
        "\n",
        "print(f\"\\n✅ Graph loaded successfully!\")\n",
        "print(f\"   Nodes: {G.number_of_nodes():,}\")\n",
        "print(f\"   Edges: {G.number_of_edges():,}\")\n",
        "print(f\"   Type: {'Undirected' if not G.is_directed() else 'Directed'}\")\n",
        "\n",
        "# Load ground-truth communities\n",
        "communities_path = \"data/raw/com-amazon.all.cmty.txt.gz\"\n",
        "print(f\"\\nLoading ground-truth communities from: {communities_path}\")\n",
        "ground_truth_dict = load_ground_truth_communities(communities_path)\n",
        "\n",
        "print(f\"\\n✅ Ground-truth communities loaded!\")\n",
        "print(f\"   Number of communities: {len(set(ground_truth_dict.values())):,}\")\n",
        "print(f\"   Number of nodes: {len(ground_truth_dict):,}\")\n",
        "print(f\"   Coverage: {len(ground_truth_dict) / G.number_of_nodes() * 100:.2f}% of graph nodes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run All Community Detection Algorithms\n",
        "\n",
        "Run all three community detection algorithms (Louvain, Label Propagation, Greedy Modularity) and time each one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all community detection algorithms\n",
        "print(\"Running all community detection algorithms...\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Note: This may take several minutes for large graphs\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "detection_results = run_all_community_detection(G, louvain_resolution=1.0, seed=42)\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"✅ All algorithms completed in {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Display Execution Times\n",
        "\n",
        "Compare the execution time for each algorithm to understand computational costs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display execution time comparison\n",
        "if 'timing' in detection_results:\n",
        "    timing_df = pd.DataFrame([\n",
        "        {'Algorithm': algo.replace('_', ' ').title(), \n",
        "         'Time (seconds)': time_taken,\n",
        "         'Time (minutes)': time_taken / 60 if time_taken else np.nan}\n",
        "        for algo, time_taken in detection_results['timing'].items()\n",
        "        if time_taken is not None\n",
        "    ])\n",
        "    timing_df = timing_df.sort_values('Time (seconds)', ascending=False)\n",
        "    \n",
        "    print(\"Execution Time Comparison\")\n",
        "    print(\"=\" * 60)\n",
        "    print(timing_df.to_string(index=False))\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nTotal computation time: {sum([t for t in detection_results['timing'].values() if t is not None]):.2f} seconds\")\n",
        "else:\n",
        "    print(\"⚠️ Timing information not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Community Size Statistics\n",
        "\n",
        "Display statistics about community sizes for each detection method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display community size statistics for each method\n",
        "print(\"Community Size Statistics by Algorithm\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for method_name in ['louvain', 'label_propagation', 'greedy_modularity']:\n",
        "    if method_name in detection_results and detection_results[method_name] is not None:\n",
        "        communities, modularity = detection_results[method_name]\n",
        "        sizes = get_community_sizes(communities)\n",
        "        \n",
        "        print(f\"\\n{method_name.replace('_', ' ').title()}:\")\n",
        "        print(f\"  Number of communities: {len(communities):,}\")\n",
        "        print(f\"  Modularity: {modularity:.6f}\")\n",
        "        print(f\"  Size statistics:\")\n",
        "        print(f\"    Min: {sizes.min()}\")\n",
        "        print(f\"    Max: {sizes.max()}\")\n",
        "        print(f\"    Mean: {sizes.mean():.2f}\")\n",
        "        print(f\"    Median: {sizes.median():.2f}\")\n",
        "        print(f\"    Std: {sizes.std():.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate Against Ground Truth\n",
        "\n",
        "Evaluate all detection methods against ground-truth communities using NMI and ARI metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all methods against ground truth\n",
        "print(\"Evaluating all methods against ground truth...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "evaluation_results = compare_all_methods(detection_results, ground_truth_dict, G)\n",
        "\n",
        "print(\"\\nEvaluation Results Comparison:\")\n",
        "print(\"=\" * 80)\n",
        "print(evaluation_results.to_string(index=False))\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare communities dictionary for visualization\n",
        "os.makedirs(\"results/figures\", exist_ok=True)\n",
        "\n",
        "communities_dict = {}\n",
        "for method in ['louvain', 'label_propagation', 'greedy_modularity']:\n",
        "    if method in detection_results and detection_results[method] is not None:\n",
        "        communities_dict[method] = detection_results[method][0]\n",
        "\n",
        "# Add ground truth (convert dict to list of sets)\n",
        "gt_communities_dict = {}\n",
        "for node, comm_id in ground_truth_dict.items():\n",
        "    if comm_id not in gt_communities_dict:\n",
        "        gt_communities_dict[comm_id] = set()\n",
        "    gt_communities_dict[comm_id].add(node)\n",
        "communities_dict['ground_truth'] = list(gt_communities_dict.values())\n",
        "\n",
        "# Plot size distribution\n",
        "print(\"Creating community size distribution plot...\")\n",
        "plot_community_size_distribution(\n",
        "    communities_dict,\n",
        "    save_path=\"results/figures/community_size_distribution.png\"\n",
        ")\n",
        "print(\"✅ Saved: results/figures/community_size_distribution.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Modularity Comparison\n",
        "\n",
        "Compare modularity scores across all algorithms.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
